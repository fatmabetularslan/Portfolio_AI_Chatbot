#!/usr/bin/env python3
"""
Local embedding generator script
Bu script CV verilerini okuyup embedding'leri hesaplar ve dosya olarak kaydeder.
Deploy sÄ±rasÄ±nda API limiti olmayacak Ã§Ã¼nkÃ¼ embedding'ler Ã¶nceden hesaplanmÄ±ÅŸ olacak.
"""

import json
import numpy as np
import pickle
from google.generativeai.embedding import embed_content
import os
from pathlib import Path

def build_chunks(cv_json):
    """CV verilerini chunk'lara bÃ¶ler"""
    chunks = []
    
    for section, content in cv_json.items():
        if section in ['name', 'title', 'location', 'email', 'phone']:
            # KiÅŸisel bilgileri tek chunk'ta birleÅŸtir
            if section == 'name':
                personal_info = f"KiÅŸisel Bilgiler: {content}"
                if 'title' in cv_json:
                    personal_info += f" - {cv_json['title']}"
                if 'location' in cv_json:
                    personal_info += f" - {cv_json['location']}"
                chunks.append(personal_info)
        elif section == 'profile':
            chunks.append(f"Profil: {content}")
        elif section == 'education':
            # EÄŸitim bilgilerini tek chunk'ta birleÅŸtir
            edu_text = "EÄŸitim: "
            for edu in content:
                edu_text += f"{edu['institution']} - {edu['degree']} ({edu['years']}); "
            chunks.append(edu_text.strip())
        elif section == 'experience':
            # Her deneyimi ayrÄ± chunk yap
            for exp in content:
                exp_text = f"Deneyim: {exp['title']} at {exp['company']} ({exp['duration']}) - {exp['description']}"
                chunks.append(exp_text)
        elif section == 'skills':
            # Yetenekleri kategorilere gÃ¶re grupla
            for category, skills in content.items():
                skills_text = f"Yetenekler - {category}: {', '.join(skills)}"
                chunks.append(skills_text)
        elif section == 'projects':
            # Her projeyi ayrÄ± chunk yap
            for project in content:
                if isinstance(project, dict):
                    proj_text = f"Proje: {project.get('name', '')} - {project.get('description', '')}"
                    chunks.append(proj_text)
        elif section == 'links':
            # Linkleri tek chunk'ta birleÅŸtir
            links_text = "Linkler: " + " | ".join([f"{k}: {v}" for k, v in content.items()])
            chunks.append(links_text)
        else:
            # DiÄŸer bÃ¶lÃ¼mler iÃ§in genel yaklaÅŸÄ±m
            if isinstance(content, (str, int, float)):
                chunks.append(f"{section}: {content}")
    
    return chunks

def generate_embeddings(chunks, api_key=None):
    """Chunk'lar iÃ§in embedding'leri hesapla"""
    print(f"ğŸ”„ {len(chunks)} chunk iÃ§in embedding hesaplanÄ±yor...")
    
    embeddings = []
    for i, chunk in enumerate(chunks):
        print(f"   ğŸ“ Chunk {i+1}/{len(chunks)}: {chunk[:50]}...")
        
        try:
            # Google API ile embedding hesapla
            result = embed_content(model="models/embedding-001", content=chunk)
            embedding = np.asarray(result["embedding"])
            embeddings.append(embedding)
            
            # Progress gÃ¶ster
            if (i + 1) % 5 == 0:
                print(f"   âœ… {i+1}/{len(chunks)} tamamlandÄ±")
                
        except Exception as e:
            print(f"   âŒ Hata (chunk {i+1}): {str(e)}")
            # SÄ±fÄ±r vektÃ¶r ekle (fallback)
            embeddings.append(np.zeros(768))
    
    print(f"âœ… TÃ¼m embedding'ler hesaplandÄ±!")
    return np.vstack(embeddings)

def save_embeddings_data(chunks, embeddings, cv_json, output_file="embeddings_data.pkl"):
    """Embedding verilerini dosyaya kaydet"""
    data = {
        'chunks': chunks,
        'embeddings': embeddings,
        'cv_json': cv_json,
        'alias': {
            "deneyim": "experience", "tecrÃ¼be": "experience",
            "eÄŸitim": "education",  "projeler": "projects",
            "Ã¶dÃ¼ller": "awards",    "yetenek": "skills",
        }
    }
    
    with open(output_file, 'wb') as f:
        pickle.dump(data, f)
    
    print(f"ğŸ’¾ Embedding verileri '{output_file}' dosyasÄ±na kaydedildi")
    print(f"   ğŸ“Š {len(chunks)} chunk, {embeddings.shape[0]}x{embeddings.shape[1]} embedding")

def main():
    """Ana fonksiyon"""
    print("ğŸš€ Local Embedding Generator")
    print("=" * 50)
    
    # CV dosyasÄ±nÄ± oku
    cv_file = "betÃ¼l-cv.json"
    if not os.path.exists(cv_file):
        print(f"âŒ CV dosyasÄ± bulunamadÄ±: {cv_file}")
        return
    
    print(f"ğŸ“– CV dosyasÄ± okunuyor: {cv_file}")
    with open(cv_file, 'r', encoding='utf-8') as f:
        cv_json = json.load(f)
    
    # Chunk'larÄ± oluÅŸtur
    print("ğŸ”¨ Chunk'lar oluÅŸturuluyor...")
    chunks = build_chunks(cv_json)
    print(f"   ğŸ“ {len(chunks)} chunk oluÅŸturuldu")
    
    # Embedding'leri hesapla
    embeddings = generate_embeddings(chunks)
    
    # Dosyaya kaydet
    save_embeddings_data(chunks, embeddings, cv_json)
    
    print("\nğŸ‰ TamamlandÄ±!")
    print("ğŸ“ Åimdi bu dosyalarÄ± Streamlit Cloud'a upload edebilirsiniz:")
    print("   - embeddings_data.pkl")
    print("   - betÃ¼l-cv.json")

if __name__ == "__main__":
    main()